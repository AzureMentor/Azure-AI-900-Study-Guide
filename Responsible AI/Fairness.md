# Fairness

- The whole point of focusing on fairness in AI systems is to make sure that the systems that we develop and we deploy reduce unfairness in our society rather than keep things at the same level or even make it worse, and that's really the goal.
- We've seen a lot of new stories over the past couple years about AI systems that are used to allocate or withhold opportunities, resources, or information in domains like criminal justice, employment and hiring, finance, credit, AI systems can reinforce existing societal stereotypes.
- Another example would be cultural denigration, we also have over and underrepresentation, there isn't a single definition that we can easily quantify and just integrate into our systems.
- Fairness relates to not just the system, the technical component, but it relates to the societal context in which the system is deployed.
- That means that fairness in the context of AI systems is a fundamentally socio-technical challenge, this means that we've got to have a greater diversity of people developing and deploying AI systems.
- What we see is that the assumptions and decisions made by teams at every stage of the AI development and deployment life cycle can introduce biases, and that's why this is such an important topic.
- This isn't something that we can just delegate to one or two people and call it quits and move on, no this is something that everybody has to be thinking about really actively.

[See Responsible AI at Microsoft](https://www.microsoft.com/en-ca/ai/responsible-ai)

[Return to Table of Contents](../README.md)