# Reliability and Safety

 - Reliability and safety is a concern for every AI system we develop.
 - Make sure that the systems we're developing are consistent with the design ideas we have, and working in the way that it is consistent with our values and principles.
 - This requires that our systems, our models, are not creating harm in the world.
 - If there are situations where they may be making mistakes, we actually push products out there with quantified and well-understood risks and harms in a way that we actually share that with our users.
 - This is the guiding principle we have with respect to reliability and safety, and it is really a concept that applies to every AI product we have in the company.
 - When we think about safety, the first examples that come to mind are self-driving cars, but is not even limited to those physical systems, physical agents. We actually worry about harm to human lives when a machine learning model is making predictions about people's health in hospitals, when they are making predictions about diagnosis, wrong systems can lead to harms for people. So those are the cases that we really worry about because the threat is to human lives, but this doesn't mean that this issue is only for those physical systems.
 - Reliability is a big concern and small mistakes may pile up when a system gets used many times across large group of people, and that's why it is a concern for everything that we build.

[See Responsible AI at Microsoft](https://www.microsoft.com/en-ca/ai/responsible-ai)

 [Return to Table of Contents](../README.md)